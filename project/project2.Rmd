---
title: "Project 2"
author: "SDS348"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
---

```{r global_options, include=FALSE}
#DO NOT EDIT THIS CHUNK OR ANYTHING ABOVE IT!
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F, tidy=T, tidy.opts=list(width.cutoff=50))
```

## Caitlyn Wilson cbw2228

**This Project is due on May 7, 2021 at 11:59pm. Please submit as an HTML file on Canvas.**

*For all questions, include the R commands/functions that you used to find your answer. Answers without supporting code will not receive credit.*

> #### Review of how to submit this assignment
>All homework assignments will be completed using R Markdown. These `.Rmd` files consist of >text/syntax (formatted using Markdown) alongside embedded R code. 
>When you have completed the assignment (by adding R code inside codeblocks and supporting text outside of the codeblocks), create your document as follows:

> - Click the arrow next to the "Knit" button (above) 
> - Choose "Knit to HTML"
> - Go to Files pane and put checkmark next to the correct HTML file
> - Click on the blue gear icon ("More") and click Export
> - Download the file and then upload to Canvas

---

### Question 0: (5 pts)

##### Introduce your dataset and each of your variables (or just your main variables if you have lots) in a paragraph. What are they measuring? How many observations?

```{R}
#Paragraph Below

```
*The `College` dataset is recorded statistics for various colleges within the United States in 1995. The information was taken from the US News and World Report. This dataframe has 777 observations on the following 18 variables (the row names are the colleges). The variable `Private` is a "No" or "Yes" level describing whether or not the college is a private or a public university. `Apps` is the recorded number of applications that were received by the college. `Accept` is the recorded number of applications that were accepted for each college. `Enroll` is the recorded number of accepted students that were enrolled. `Top10perc` is the percent of newly enrolled students that came from the top 10% of their high school class. `Top25perc` is the percent of newly enrolled students that came from the top 25% of their high school class. `F.Undergard` is the recorded number of undergraduates that are fulltime (enrolled in 12+ hours). `P.Undergrad` is the recorded number of undergraduates that are part-time (enrolled in fewer than 12 hours). `Outstate` refers to the recorded number of out-of-state tuition for each college. `Room.Board` is the average room and board costs for each college. `Books` is the estimated cost for books for each college. `Personal` is the estimation of personal spending per student at every college. `PhD` is the percent of faculty with Ph.D.'s. `Terminal` is the percent of faculty that have a terminal degree. `S.F.Ratio` is the student to faculty ratio for each college. `Perc.alumni` is the percent of alumni who donate to their colleges. `Expend` is the average instructional expenditure per student for each college. `Grade.Rate` is the graduation rate for each college.*

---

### Question 1: (15 pts)

##### Perform a MANOVA testing whether any of your numeric variables (or a subset of them, if including them all is unreasonable or doesn't make sense) show a mean difference across levels of one of your categorical variables (3). If they do, perform univariate ANOVAs to find response(s) showing a mean difference across groups (3), and perform post-hoc t tests to find which groups differ (3). Discuss the number of tests you have performed, calculate the probability of at least one type I error (if unadjusted), and adjust the significance level accordingly (bonferroni correction) before discussing significant differences (3). Briefly discuss some of the MANOVA assumptions and whether or not they are likely to have been met here (no need for anything too in-depth) (2).

```{R}

library(dplyr)
library(tidyverse)
library(ggplot2)
library(ISLR)
library(lmtest)
library(plotROC)

college <- tibble::rownames_to_column(College, "College")
data("College")

#H0: For each response variable, the means of all groups are equal
#HA: For at least 1 response variable, at least 1 group mean differs

library(rstatix)
group<-college$Private
DVs<-college %>% select(Apps,Accept,Enroll,F.Undergrad,P.Undergrad,Room.Board,Books,Grad.Rate)
sapply(split(DVs,group),mshapiro_test)

man1<-manova(cbind(Apps,Accept,Enroll,F.Undergrad,P.Undergrad,Room.Board,Books,Grad.Rate)~Private,data=college)
summary(man1)
#Findings: For at least one of the variables listed, private vs. public is different from the other.

summary.aov(man1)
#For `Apps`, `Accept`, `Enroll`, `F.Undergrad`, `P.Undergrad`, `Room.Board`, and `Grad.Rate` (everything listed except for `Books`) there are differences between whether or not the college is `Private`.

college %>% group_by(Private) %>% summarize(mean(Accept),mean(Enroll),mean(F.Undergrad),mean(P.Undergrad),mean(Room.Board),mean(Grad.Rate))



1+8
#A total of 9 tests were done.
#Probability of at least one Type 1 error is 0.3697506. (36.98% chance of making at least one Type 1 error)
1-(0.95)^9

#The Bonferroni correction is 0.005555556. Rejecting at that are less than this value will keep the overall Type 1 error rate at 5% rather than 36.98%.
0.05/9

#Even after adjusting the significance level accordingly, everything still remains as discussed in terms of significance (everything is significant except for `Books`), but violations were made to the assumptions.



```
*Significant differences were found among whether or not the school is `Private` for at least one of the dependent variables, Pillai trace = 0.51, F(8,768) = 100.65, p < 0.001. Univariate ANOVAs for each dependent variable were conducted as follow-up tests to the MANOVA, using the Bonferroni method for controlling Type 1 error rates for multiple comparisons. The univariate ANOVAs for `Apps` (F(1,775)=177.91,p<0.0001), `Accept` (F(1,775)=226.12, p<0.0001), `Enroll` (F(1,775)=368.94,p<0.0001), `F.Undergrad` (F(1,775)=472.82,p<0.0001), `P.Undergrad` (F(1,775)=199.09,p<0.0001), `Room.Board` (F(1,775)=101.66, p<0.0001), and `Grad.Rate`(F(1,775)=98.737,p<0.0001) were significant. Post hoc analysis was performed conducting pairwise comparisons between which category (Private or Public) differed in the dependent variables (`Apps`, `Accept`, `Enroll`, `F.Undergrad`, `P.Undergrad`, `Room.Board`,`Grad.Rate` and `Books`). The two groups (Private or Public) were found to differ significantly from each other in terms of all of the dependent variables (`Apps`, `Accept`, `Enroll`, `F.Undergrad`, `P.Undergrad`, `Room.Board`,`Grad.Rate`) except for `Books` after adjusting for multiple comparisons (bonferroni Î± = 0.5/9 = 0.005555556). The following MANOVA assumptions were not met, which include 1) random samples, with independent observations, 2) multivariate normality of DVs, 3) homogeneity of within-group covariance matrices, 4) linear relationships among DVs, 5) no extreme univaraite or multivariate outliers, and 6) no multicollinearity.*

### Question 2: (10 pts)

##### Perform some kind of randomization test on your data (that makes sense). The statistic can be anything you want (mean difference, correlation, F-statistic/ANOVA, chi-squared), etc. State null and alternative hypotheses, perform the test, and interpret the results (7). Create a plot visualizing the null distribution and the test statistic (3).

```{R}

library(dplyr)
obs_F<-55.48
summary(aov(Expend~Private,data=college))
new<-college
Fs <- replicate(5000,{ #do everything in curly braces 5000 times and save the output
  new <- college%>%mutate(Expend=sample(Expend)) #randomly permute response variable (y)
  #compute the SSW and SSB by hand
  SSW <- new %>% group_by(Private) %>% summarize(SSW=sum((Expend-mean(Expend))^2)) %>%
    summarize(sum(SSW)) %>% pull
  SSB <- new %>% mutate(mean=mean(Expend)) %>% group_by(Private) %>%
    mutate(groupmean=mean(Expend)) %>% summarize(SSB=sum((mean-groupmean)^2)) %>%
    summarize(sum(SSB))%>%pull
  (SSB/1)/(SSW/775)
})

hist(Fs, prob=T); abline(v = obs_F, col="red",add=T)

mean(Fs>obs_F)

```
*#The null hypothesis is the population mean of out of state tuition for Private colleges is equal to the mean population of of out of state tuition for colleges that are NOT private. The alternative hypothesis is that at least one of the means is different from each other. The p-value is effectively 0. All of our 5000 F statistics generated under the null hypothesis were smaller than our actual F statistic (55.48). Definitely reject the null hypothesis and conclude that the groups differ significantly!*

### Question 3: (40 pts)

##### Build a linear regression model predicting one of your response variables from at least 2 other variables, including their interaction. Mean-center any numeric variables involved in the interaction.

```{R}

bc <- data.frame(Books_c = college$Books - mean(college$Books, na.rm=T))
college<-data.frame(college,bc)

rbc <- data.frame(Room.Board_c = college$Room.Board - mean(college$Room.Board,na.rm=T))
college<-data.frame(college,rbc)

fit3 <- lm(Expend ~ Books_c*Private, data = college)
summary(fit3)

college %>% select(Expend, Books_c, Private) %>% na.omit %>% 
    ggplot(aes(Books_c, Expend, color = Private)) + 
    geom_point() + geom_smooth(method = "lm") + geom_vline(xintercept = mean(college$Books_c, 
    na.rm = T), lty = 2)



#Linearity
##looking at the mean difference in terms of the two groups (private vs. public)

resids<-lm(Expend~Books*Private, data=college)$residuals

library(tidyverse)
library(ggplot2)

fit3residuals<-fit3$residuals
fit3fit<-fit3$fitted.values
ggplot()+geom_point(aes(fit3fit,fit3residuals))+geom_hline(yintercept=0,color='red')
ggplot()+geom_histogram(aes(fit3residuals), bins=20)
ggplot()+geom_qq(aes(sample=fit3residuals))+geom_qq_line(aes(sample=fit3residuals))
#looking at the residuals, there is a slight fanning out pattern that makes it less likely to determine the dataset to be completely linear and normal.

ggplot()+geom_histogram(aes(resids),bins=10)

# Homoskedasticity

ggplot(college,aes(Books,Expend,color=Private))+geom_point()
#There is a slight fanning out pattern, so it is difficult to tell whether or not it violates the assumption of equal variance. 

library(sandwich)
bptest(fit3)
#H0: homoskedastic assumption is met
#HA: homoskedastic assumption is not met 
#Findings: because the p-value is greater than 0.0t, the H0 was failed to be rejected.

coeftest(fit3,vcov=vcovHC(fit3))



```
*The intercept is simply the mean of the value that was centered on. With `Books` centered at the mean, this means that `Books` is centered in the range of the rest of the data and that context influenced all of the variables. The mean/predicted amount for average instructional expenditure per students at colleges that are NOT private with spend average amount for the costs of books is 7429.349 units of expenditure. Private colleges with an average amount of book costs have predicted amount of units of intstructional expenditure 3063.075 higher than colleges that are NOT private with an average amount of Book costs. Colleges that are not private have 5.798 more units of instructional expenditure than private colleges. The proportion of the variation in the outcome explained by the model is  0.07796. After redoing the regression using heteroskadsticity robust standard errors, the t-value for `Books_c` increased from 2.280 to 4.6577, making the standard error decrease. The t-value for Private colleges increased from 7.581 to 10.3153, making the standard error decrease. The t-value for the interaction between Books_c and Private colleges decreased from -0.909 to -1.3868. The p-value significance for all of the variables remained the same (Book_c and Private colleges were significant, while the interactio between Books_c and Private colleges was not). This shows that Books_c and Private colleges does explain some of the variation in the amount of instructional expenditure.*

### Question 4: (5 pts)

##### Rerun same regression model (with the interaction), but this time compute bootstrapped standard errors (either by resampling observations or residuals). Discuss any changes you observe in SEs and p-values using these SEs compared to the original SEs and the robust SEs).

```{R}

set.seed(348)

boot_dat<- sample_frac(college, replace=T)

samp_distn<-replicate(5000, {
boot_dat <- sample_frac(college, replace=T) #take bootstrap sample of rows
fit <- lm(Expend~Books_c*Private, data=boot_dat) #fit model on bootstrap sample
coef(fit) #save coefs
})
## Estimated SEs

samp_distn %>% t %>% as.data.frame %>% summarize_all(sd)




```
*The estimated standard error in #3 is slightly smaller (relatively the same) for the intercept, which is 176.4264 to 176.4348 respectively. The estimated standard error in #3 for Book_c (1.2447 to 1.250056) and Private colleges (296.9457 to 298.9327), is slightly smaller, but relatively the same. For the interaction between Book_c and Private colleges, the estimated standard error in #3 is slightly larger (relatively the same) from 1.8462 to 1.833851. *


### Question 5: (30 pts)

##### Fit a logistic regression model predicting a binary variable (if you don't have one, make/get one) from at least two explanatory variables (interaction not necessary). 

```{R}

college <- college %>% mutate(y = ifelse(Private == "Yes", 1,0))
fit5 <- glm(y ~ Personal+S.F.Ratio, data = college, family = binomial(link = "logit"))
summary(fit5)
exp(coef(fit5))


fit5_1<-glm(y~Personal+S.F.Ratio,data=college,family="binomial")
probs5<-predict(fit5_1,type="response") #get predicted probs from model

## Confusion matrix
table(truth=college$y,predict=as.numeric(probs5>0.5))%>%addmargins

#Accuracy = 0.8146718
(106+527)/777

#TNR (specificity) = 0.5
(106/212)

#TPR (sensitivity) = 0.9327434
(527/565)

#Precision = 0.8325434
(527/633)


############################################ 
class_diag <- function(probs, truth) {
    
    tab <- table(factor(probs > 0.5, levels = c("FALSE", "TRUE")), 
        truth)
    acc = sum(diag(tab))/sum(tab)
    sens = tab[2, 2]/colSums(tab)[2]
    spec = tab[1, 1]/colSums(tab)[1]
    ppv = tab[2, 2]/rowSums(tab)[2]
    
    if (is.numeric(truth) == FALSE & is.logical(truth) == FALSE) 
        truth <- as.numeric(truth) - 1
    
    # CALCULATE EXACT AUC
    ord <- order(probs, decreasing = TRUE)
    probs <- probs[ord]
    truth <- truth[ord]
    
    TPR = cumsum(truth)/max(1, sum(truth))
    FPR = cumsum(!truth)/max(1, sum(!truth))
    
    dup <- c(probs[-1] >= probs[-length(probs)], FALSE)
    TPR <- c(0, TPR[!dup], 1)
    FPR <- c(0, FPR[!dup], 1)
    
    n <- length(TPR)
    auc <- sum(((TPR[-1] + TPR[-n])/2) * (FPR[-1] - FPR[-n]))
    
    data.frame(acc, sens, spec, ppv, auc)
}
############################################ 

class_diag(probs5,college$Private)
#The AUC value is 0.8545667.


college$logit<-predict(fit5_1,type="link")

college%>%ggplot()+geom_density(aes(logit,color=Private,fill=Private), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab("logit (log-odds)")+
  geom_rug(aes(logit,color=Private))+
  geom_text(x=-5,y=.07,label="TN = 431")+
  geom_text(x=-1.75,y=.008,label="FN = 19")+
  geom_text(x=1,y=.006,label="FP = 13")+
  geom_text(x=5,y=.04,label="TP = 220")


ROCplot1 <- ggplot(college) + geom_roc(aes(d = y, 
    m = probs5), n.cuts = 0)

ROCplot1
calc_auc(ROCplot1)
#AUC is 0.8545667	


```
*Every one-unit decrease in average personal spending multiplies the odds of the college being a private college by 0.9989998. Every one-unit decrease in average student to faculty ratio multiplies the odds of the college being a private college by 0.7112906. Based on the confusion matrix, the accuracy is 0.81, the speicificity is 0.5, the sensitivity is 0.9327434, the precision is 0.8325434 and the AUC is 0.8545667. The accuracy and the sensitivity is fairly good, along with the precision. The AUC is considered to be "good".*


### Question 6: (25 pts)

##### Perform a logistic regression predicting the same binary response variable from *ALL* of the rest of your variables (the more, the better!) 

```{R}

fit6<-glm(y~Apps+Accept+Enroll+Personal+S.F.Ratio,data=college,family="binomial")

library(ISLR)
data("College")
college <- tibble::rownames_to_column(College, "College")
college <- college %>% mutate(y = ifelse(Private == "Yes", 1,0))
college <- college %>% dplyr::select(-College,-Private)




#############################################################
class_diag <- function(probs, truth) {
    
    tab <- table(factor(probs > 0.5, levels = c("FALSE", "TRUE")), 
        truth)
    acc = sum(diag(tab))/sum(tab)
    sens = tab[2, 2]/colSums(tab)[2]
    spec = tab[1, 1]/colSums(tab)[1]
    ppv = tab[2, 2]/rowSums(tab)[2]
    
    if (is.numeric(truth) == FALSE & is.logical(truth) == FALSE) 
        truth <- as.numeric(truth) - 1
    
    # CALCULATE EXACT AUC
    ord <- order(probs, decreasing = TRUE)
    probs <- probs[ord]
    truth <- truth[ord]
    
    TPR = cumsum(truth)/max(1, sum(truth))
    FPR = cumsum(!truth)/max(1, sum(!truth))
    
    dup <- c(probs[-1] >= probs[-length(probs)], FALSE)
    TPR <- c(0, TPR[!dup], 1)
    FPR <- c(0, FPR[!dup], 1)
    
    n <- length(TPR)
    auc <- sum(((TPR[-1] + TPR[-n])/2) * (FPR[-1] - FPR[-n]))
    
    data.frame(acc, sens, spec, ppv, auc)
}
#############################################################

fit<-glm(y ~ .,data=college,family="binomial")
probs<-predict(fit,type="response")
class_diag(probs,college$y)


set.seed(1234)
k = 10

data <- college[sample(nrow(college)), ]
folds <- cut(seq(1:nrow(college)), breaks = k, labels = F)  #create folds
diags <- NULL
for (i in 1:k) {
    train <- data[folds != i, ]
    test <- data[folds == i, ]
    truth <- test$y
    fit <- glm(y ~ ., data = train, family = "binomial")
    probs <- predict(fit, newdata = test, type = "response")
    diags <- rbind(diags, class_diag(probs, truth))
}

summarize_all(diags, mean)


library(glmnet)

y <- as.matrix(college$y)
x <- model.matrix(y ~ ., data = college)
cv <- cv.glmnet(x, y, family = "binomial")
lasso <- glmnet(x, y, family = "binomial", lambda = cv$lambda.1se)
coef(lasso)


lassop <- college %>% select(Apps,F.Undergrad,P.Undergrad, Outstate, PhD, Terminal, S.F.Ratio,perc.alumni,Grad.Rate,y)

set.seed(1234)
k = 10

data <- lassop[sample(nrow(lassop)), ]
folds <- cut(seq(1:nrow(lassop)), breaks = k, labels = F)  #create folds
diags <- NULL
for (i in 1:k) {
    train <- data[folds != i, ]
    test <- data[folds == i, ]
    truth <- test$y
    fit <- glm(y ~ ., data = train, family = "binomial")
    probs <- predict(fit, newdata = test, type = "response")
    diags <- rbind(diags, class_diag(probs, truth))
}

summarize_all(diags, mean)


```
*The performance of the in-sample is excellent, wieth all of the classification diagnostics being greater than 0.90. There was substantial decrease in the average out-of-sample classification diagnostics compared to the in-sample classification diagnostics. Although the values still remain fairly good, the specificity was the most that was impacted - dropping from 0.9009434 to 0.8823868. The AUC remains to be categorized as "great". The variables that were retained after choosing lambda that gave the simplet model who accuracy was near that of the best included `Apps`, `F.Undergrad`, `P.Undergrad`, `Outstate`, `PhD`, `Terminal`, `S.F.Ratio`, `perc.alumni`, and `Grad.Rate`. Comparing the previous out of sample classification diagnostics to the lasso-selected variables, overall, there was a noticeable increase in the improvement in the classifications. *

```{R, echo=F}
## DO NOT DELETE OR MODIFY THIS CHUNK: IT MUST BE PRESENT TO RECEIVE CREDIT FOR THE ASSIGNMENT
sessionInfo(); Sys.time(); Sys.info()
```
